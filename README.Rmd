---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# kgrams

<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://www.tidyverse.org/lifecycle/#experimental)
[![CircleCI build status](https://circleci.com/gh/vgherard/kgrams.svg?style=svg)](https://circleci.com/gh/vgherard/kgrams)
[![AppVeyor build status](https://ci.appveyor.com/api/projects/status/github/vgherard/kgrams?branch=main&svg=true)](https://ci.appveyor.com/project/vgherard/kgrams)
[![R-CMD-check](https://github.com/vgherard/kgrams/workflows/R-CMD-check/badge.svg)](https://github.com/vgherard/kgrams/actions)
[![Codecov test coverage](https://codecov.io/gh/vgherard/kgrams/branch/main/graph/badge.svg)](https://codecov.io/gh/vgherard/kgrams?branch=main)
<!-- badges: end -->

`kgrams` provides tools for training and evaluating k-gram language models, including several probability smoothing methods, perplexity computations, random text generation and more.

## Installation

You can install the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("vgherard/kgrams")
```
## Example

This example shows how to train a modified Kneser-Ney 4-gram model on Shakespeare's "Much Ado About Nothing" using `kgrams` and generate random text
from the model's distribution.

```{r}
library(kgrams)
# Get k-gram frequency counts from text, for k = 1:4
freqs <- kgram_freqs(kgrams::much_ado, N = 4)
# Build modified Kneser-Ney 4-gram model, with discount parameters D1, D2, D3.
mkn <- language_model(freqs, smoother = "mkn", D1 = 0.25, D2 = 0.5, D3 = 0.75)
```

We can now use this `language_model` to compute sentence and word continuation probabilities:

```{r}
# Compute sentence probabilities
probability(c("did he break out into tears ?",
              "we are predicting sentence probabilities ."
              ), 
            model = mkn
            )
# Compute word continuation probabilities
probability(c("tears", "pieces") %|% "did he break out into", model = mkn)
```

Here are some sentences sampled from the language model's distribution at temperatures `t = c(1, 0.1, 10)`:

```{r}
# Compute sentence probabilities
set.seed(840)
sample_sentences(model = mkn, n = 3, max_length = 10, t = 1)
sample_sentences(model = mkn, n = 3, max_length = 10, t = 0.1)
sample_sentences(model = mkn, n = 3, max_length = 10, t = 10)
```

## Website
[website](https://vgherard.github.io/kgrams/)
