% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/perplexity.R
\name{perplexity}
\alias{perplexity}
\alias{perplexity.character}
\title{Language Model Probabilities}
\usage{
perplexity(
  text,
  model,
  .preprocess = attr(model, ".preprocess"),
  .tokenize_senteces = attr(model, ".tokenize_sentences"),
  ...
)

\method{perplexity}{character}(
  text,
  model,
  .preprocess = attr(model, ".preprocess"),
  .tokenize_senteces = attr(model, ".tokenize_sentences"),
  ...
)
}
\arguments{
\item{text}{a character vector or connection. Test corpus from which
language model perplexity is computed.}

\item{model}{either an object of class \code{language_model}, or a
\code{kgram_freqs} object. The language model from which probabilities
are computed.}

\item{.preprocess}{a function taking a character vector as input and
returning a character vector as output. Preprocessing transformation
applied to input before computing perplexity.}

\item{.tokenize_sentences}{a function taking a character vector as input and
returning a character vector as output. Optional sentence tokenization step
applied before computing perplexity.}

\item{batch_size}{a length one positive integer or \code{NULL}.
Size of text batches when reading text from a \code{connection}.
If \code{NULL}, all input text is processed in a single batch.}
}
\value{
a number. Perplexity of the language model on the test corpus.
}
\description{
Compute sentence probabilities and word continuation conditional
probabilities from a language model
}
\details{

}
\author{
Valerio Gherardi
}
